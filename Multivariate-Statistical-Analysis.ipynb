{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6289912c-2628-4476-88e7-17121b4a07c4",
   "metadata": {},
   "source": [
    "‏بخش اول: فواصل اطمینان چند متغیره\n",
    "‏\n",
    "‏**مقدمه و تئوری**\n",
    "‏\n",
    "‏محققان و تحلیلگران اغلب در مباحث آمار و داده کاوی از عبارت **فاصله اطمینان (Confidence Interval)** استفاده می‌کنند تا نشان دهند که تقریباً مطمئن هستند یک فاصله یا محدوده‌ای، شامل پارامتر مورد نظر جامعه است. برای ساخت این فاصله، ابتدا باید یک **کمیت محوری (Pivototal Quantity)** تعریف کرد. کمیت محوری تابعی از نمونه تصادفی و پارامترهاست که توزیع آن به پارامترهای مجهول بستگی ندارد.\n",
    "‏\n",
    "‏**ناحیه اطمینان برای بردار میانگین:**\n",
    "‏\n",
    "‏برای بردار میانگین یک توزیع نرمال p-متغیره، از آماره **T² هتلینگ** برای ساخت ناحیه اطمینان استفاده می‌شود. این ناحیه شامل تمام بردارهای میانگین μ است که در نابرابری زیر صدق می‌کنند:\n",
    "‏\n",
    "$$\n",
    "N(\\overline{x}-\\mu)'S^{-1}(\\overline{x}-\\mu) \\le \\frac{(N-1)p}{N-p}F_{p,N-p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e551c-2b37-437d-b534-b28b16a9ee9c",
   "metadata": {},
   "source": [
    "‏**انواع فواصل اطمینان:**\n",
    "‏\n",
    "‏* **فواصل اطمینان تکی (Simultaneous):** برای هر مؤلفه میانگین به صورت جداگانه و بدون در نظر گرفتن همبستگی با سایر مؤلفه‌ها محاسبه می‌شود.\n",
    "‏\n",
    "‏* **فواصل اطمینان همزمان (T-squared):** این فواصل با در نظر گرفتن ساختار همبستگی بین متغیرها ساخته می‌شوند و تضمین می‌کنند که همزمان تمام میانگین‌های واقعی با اطمینان مشخصی در بازه‌های خود قرار دارند. این بازه‌ها معمولاً از فواصل تکی پهن‌تر هستند.\n",
    "‏\n",
    "‏* **فواصل اطمینان بونفرونی (Bonferroni):** این روش یک حد وسط بین دو روش قبلی است و برای تعداد محدودی از مقایسه‌های همزمان به کار می‌رود. این فواصل از فواصل T-squared باریک‌تر اما از فواصل تکی پهن‌تر هستند."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e89bc5d-e3ef-4fee-b27a-2cc4f0a66d78",
   "metadata": {},
   "source": [
    "‏بخش دوم: تحلیل مؤلفه‌های اصلی (PCA) و رگرسیون مؤلفه‌های اصلی (PCR)\n",
    "‏\n",
    "‏**تحلیل مؤلفه‌های اصلی (PCA)**\n",
    "‏\n",
    "‏**مقدمه و تئوری**\n",
    "‏\n",
    "‏تحلیل مؤلفه‌های اصلی (PCA) روشی برای کاهش بعد (Dimension Reduction) است. هدف اصلی آن، تبدیل مجموعه‌ای از متغیرهای همبسته به مجموعه‌ای جدید از متغیرهای ناهمبسته (متعامد) به نام **مؤلفه‌های اصلی** است.\n",
    "‏\n",
    "‏* اولین مؤلفه اصلی، ترکیبی خطی از متغیرهای اولیه است که بیشترین واریانس داده‌ها را در خود جای داده است.\n",
    "‏* دومین مؤلفه اصلی، بیشترین واریانس باقی‌مانده را توضیح می‌دهد و بر اولین مؤلفه عمود (ناهمبسته) است.\n",
    "‏\n",
    "‏این فرآیند از طریق **تجزیه مقدار ویژه (Eigenvalue Decomposition)** ماتریس کوواریانس یا همبستگی داده‌ها انجام می‌شود. واریانس هر مؤلفه اصلی برابر با مقدار ویژه متناظر آن است."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82aed05-a95f-48b6-806a-f087c084f5f1",
   "metadata": {},
   "source": [
    "‏پیاده‌سازی در R (مثال داده‌های mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af2fd8f0-91b8-4bd9-a3bd-f77d33d422e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فراخوانی کتابخانه و دیتاست\n",
    "library(dplyr)\n",
    "data(mtcars)\n",
    "\n",
    "# انجام تحلیل مولفه‌های اصلی\n",
    "# scale=TRUE داده‌ها را استاندارد می‌کند (میانگین صفر و واریانس یک)\n",
    "my_pca <- prcomp(mtcars, scale = TRUE, center = TRUE)\n",
    "\n",
    "# مشاهده خلاصه نتایج\n",
    "summary(my_pca)\n",
    "\n",
    "# رسم نمودار Biplot برای مشاهده رابطه متغیرها و مشاهدات با دو مولفه اول\n",
    "biplot(my_pca, main = \"Biplot\", scale = 0)\n",
    "\n",
    "# محاسبه واریانس هر مولفه\n",
    "my_pca.var <- my_pca$sdev^2\n",
    "\n",
    "# محاسبه نسبت واریانس توضیح داده شده توسط هر مولفه\n",
    "prop_var_explained <- my_pca.var / sum(my_pca.var)\n",
    "\n",
    "# رسم نمودار سنگ‌ریزه (Scree Plot) برای انتخاب تعداد مناسب مولفه‌ها\n",
    "plot(prop_var_explained, xlab = \"Principal Component\", \n",
    "     ylab = \"Proportion of Variance Explained\", type = \"b\", \n",
    "     main = \"Scree Plot\")\n",
    "\n",
    "# رسم نمودار واریانس تجمعی\n",
    "plot(cumsum(prop_var_explained), xlab = \"Principal Component\", \n",
    "     ylab = \"Cumulative Proportion of Variance Explained\", type = \"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89168a45-379a-4cac-ac74-478a35332c01",
   "metadata": {},
   "source": [
    "‏**تحلیل:** نمودار سنگ‌ریزه و واریانس تجمعی نشان می‌دهند که تقریباً ۹۰٪ از کل واریانس داده‌ها توسط ۴ مؤلفه اصلی اول توضیح داده می‌شود. این یعنی می‌توانیم ۱۱ متغیر اولیه را به ۴ مؤلفه کاهش دهیم بدون اینکه اطلاعات زیادی از دست برود."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b2204-13dd-411b-a8e5-451820d15aaa",
   "metadata": {},
   "source": [
    "‏**رگرسیون مؤلفه‌های اصلی (PCR)**\n",
    "‏\n",
    "‏**مقدمه و تئوری**\n",
    "‏\n",
    "‏وقتی متغیرهای پیش‌بین در یک مدل رگرسیونی دچار هم‌خطی (Collinearity) باشند، برآورد ضرایب مدل ناپایدار و غیرقابل اعتماد می‌شود. رگرسیون مؤلفه‌های اصلی (PCR) راهی برای حل این مشکل است. این روش در دو گام انجام می‌شود:\n",
    "‏\n",
    "‏1.  استخراج مؤلفه‌های اصلی از متغیرهای پیش‌بین (که ناهمبسته هستند).\n",
    "‏2.  انجام رگرسیون روی این مؤلفه‌ها به عنوان متغیرهای مستقل جدید."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c6e30-b84e-4dc8-94c9-f4ae51e8830f",
   "metadata": {},
   "source": [
    "‏پیاده‌سازی در R (مثال داده‌های mtcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "288f29b5-d400-4912-89ce-e3f2610e92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فراخوانی کتابخانه pls\n",
    "library(pls)\n",
    "\n",
    "# ساخت مدل PCR با اعتبارسنجی متقابل (Cross-validation)\n",
    "# متغیر پاسخ mpg و بقیه متغیرها پیش‌بین هستند\n",
    "pcr_model <- pcr(mpg ~ ., data = mtcars, scale = TRUE, validation = \"CV\")\n",
    "\n",
    "# مشاهده خلاصه مدل\n",
    "summary(pcr_model)\n",
    "\n",
    "# رسم نمودار برای انتخاب تعداد بهینه مولفه‌ها بر اساس خطای پیش‌بینی\n",
    "validationplot(pcr_model, val.type = \"MSEP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc0732-a0e4-48a2-a2d1-585600dbef77",
   "metadata": {},
   "source": [
    "‏**تحلیل:** نمودار MSEP (میانگین مربعات خطای پیش‌بینی) نشان می‌دهد که خطا با ۴ مؤلفه به کمترین میزان خود می‌رسد و پس از آن تغییر چشمگیری ندارد. بنابراین، استفاده از ۴ مؤلفه برای ساخت مدل رگرسیونی بهینه است."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07087542-4565-46b1-abf0-20e057b8247c",
   "metadata": {},
   "source": [
    "‏بخش سوم: تحلیل عاملی اکتشافی (EFA)\n",
    "‏\n",
    "‏**مقدمه و تئوری**\n",
    "‏\n",
    "‏تحلیل عاملی (Factor Analysis) روشی برای شناسایی ساختارهای پنهان (Latent Variables or Factors) در داده‌هاست. فرض اصلی این است که همبستگی بین متغیرهای مشاهده‌شده، ناشی از چند عامل مشترک و غیرقابل مشاهده است. برخلاف PCA که هدفش حداکثر کردن واریانس است، هدف EFA توضیح دادن کوواریانس (همبستگی) بین متغیرهاست.\n",
    "‏\n",
    "‏این روش دو نوع اصلی دارد:\n",
    "‏\n",
    "‏* **تحلیل عاملی اکتشافی (EFA):** زمانی که هیچ فرضیه قبلی در مورد ساختار عامل‌ها وجود ندارد و هدف کشف این ساختار است.\n",
    "‏* **تحلیل عاملی تأییدی (CFA):** زمانی که یک مدل نظری از قبل وجود دارد و هدف، آزمون کردن آن مدل با داده‌هاست.\n",
    "‏\n",
    "‏**پیاده‌سازی در R (مثال پرسشنامه)**\n",
    "‏\n",
    "‏قبل از تحلیل عاملی، باید از مناسب بودن داده‌ها اطمینان حاصل کرد:\n",
    "‏\n",
    "‏* **آزمون آلفای کرونباخ:** پایایی درونی گویه‌ها را می‌سنجد. مقدار بالای ۰.۷ قابل قبول است.\n",
    "‏* **شاخص KMO:** کفایت نمونه‌گیری را می‌سنجد. مقدار بالای ۰.۶ مناسب است.\n",
    "‏* **آزمون کرویت بارتلت:** فرض صفر \"عدم همبستگی بین متغیرها\" را آزمون می‌کند. برای انجام تحلیل عاملی، این فرض باید رد شود (p-value < 0.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b3e4894-4720-4cba-9456-8bb80930327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فراخوانی پکیج‌های مورد نیاز\n",
    "library(psych)\n",
    "library(GPArotation)\n",
    "\n",
    "# 1. دیتاست bfi را از پکیج psych بارگذاری می‌کنیم\n",
    "data(bfi)\n",
    "\n",
    "# 2. فقط ۲۵ ستون اول که مربوط به سوالات پرسشنامه است را انتخاب می‌کنیم.\n",
    "#    همچنین، سطرهای دارای مقدار گمشده (NA) را حذف می‌کنیم تا کد به خطا نخورد.\n",
    "my_data <- na.omit(bfi[, 1:25])\n",
    "\n",
    "# فرض می‌کنیم 'my_data' دیتافریم پرسشنامه است\n",
    "# 1. بررسی مناسب بودن داده‌ها\n",
    "KMO(my_data)\n",
    "cortest.bartlett(my_data)\n",
    "\n",
    "# 2. تعیین تعداد مناسب عامل‌ها با نمودار سنگ‌ریزه\n",
    "scree(my_data, factors = TRUE)\n",
    "\n",
    "# 3. انجام تحلیل عاملی با 3 عامل و چرخش Varimax\n",
    "# چرخش (Rotation) به ساده‌سازی و تفسیرپذیری بهتر عامل‌ها کمک می‌کند\n",
    "fa_model <- fa(my_data, nfactors = 3, rotate = \"varimax\")\n",
    "\n",
    "# مشاهده نتایج و بارهای عاملی\n",
    "print(fa_model)\n",
    "\n",
    "# رسم دیاگرام عامل‌ها\n",
    "fa.diagram(fa_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614633b-f821-4884-a5df-6688ca294c26",
   "metadata": {},
   "source": [
    "‏**تحلیل:** نتایج نشان می‌دهد که کدام سوالات پرسشنامه تحت کدام عامل مشترک قرار می‌گیرند. با بررسی محتوای سوالات هر عامل، می‌توان آن عامل را نام‌گذاری کرد (مثلاً عامل \"اجتناب از صمیمیت\" یا \"اضطراب در رابطه\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091816c2-91b7-47d6-8108-cabacfcf5846",
   "metadata": {},
   "source": [
    "‏بخش چهارم: تحلیل ممیزی خطی (LDA)\n",
    "‏\n",
    "‏**مقدمه و تئوری**\n",
    "‏\n",
    "‏تحلیل ممیزی (Discriminant Analysis) یک روش طبقه‌بندی (Classification) است. هدف آن، پیدا کردن ترکیبات خطی از متغیرهای پیش‌بین است که به بهترین شکل ممکن گروه‌های مختلف را از یکدیگر جدا (ممیزی) کنند. مدل LDA سپس می‌تواند برای پیش‌بینی عضویت یک مشاهده جدید در یکی از این گروه‌ها استفاده شود.\n",
    "‏\n",
    "‏**پیاده‌سازی در R (مثال داده‌های گل زنبق iris)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "858e90ee-531f-4ccf-ba6b-6948e6b69d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فراخوانی پکیج مورد نیاز\n",
    "library(MASS)\n",
    "library(caret)\n",
    "\n",
    "# استفاده از دیتاست iris\n",
    "data <- iris\n",
    "\n",
    "# 1. تقسیم داده به مجموعه آموزشی و آزمایشی\n",
    "set.seed(123) # برای تکرارپذیری\n",
    "training.samples <- createDataPartition(data$Species, p = 0.8, list = FALSE)\n",
    "train.data <- data[training.samples, ]\n",
    "test.data <- data[-training.samples, ]\n",
    "\n",
    "# 2. ساخت مدل LDA روی داده‌های آموزشی\n",
    "model <- lda(Species ~ ., data = train.data)\n",
    "\n",
    "# 3. پیش‌بینی روی داده‌های آزمایشی\n",
    "predictions <- predict(model, test.data)\n",
    "\n",
    "# 4. ارزیابی دقت مدل با ماتریس درهم‌ریختگی\n",
    "confusionMatrix(predictions$class, test.data$Species)\n",
    "\n",
    "# رسم نتایج\n",
    "plot(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f2fd7-5a50-467b-98bf-250aa9b227d9",
   "metadata": {},
   "source": [
    "‏**تحلیل:** خروجی مدل LDA ضرایب ترکیبات خطی (توابع ممیزی) را نشان می‌دهد. ماتریس درهم‌ریختگی نیز دقت مدل در طبقه‌بندی نمونه‌های جدید را مشخص می‌کند. نمودار `plot(model)` به صورت بصری نشان می‌دهد که گروه‌ها تا چه حد توسط توابع ممیزی از هم جدا شده‌اند."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
